{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis (Kaggle)\n",
    "\n",
    "This challenge is a classification problem for text data that classify phrases (or sentense) on a scale of five values: negative, somewhat negative, neutral, somewhat positive, positive. Obstacles like sentence negation, sarcasm, terseness, language ambiguity, and many others make this task very challenging."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset\n",
    "\n",
    "The dataset is comprised of tab-separated files with phrases from the Rotten Tomatoes dataset. The train/test split has been preserved for the purposes of benchmarking, but the sentences have been shuffled from their original order. Each Sentence has been parsed into many phrases by the Stanford parser. Each phrase has a PhraseId. Each sentence has a SentenceId. Phrases that are repeated (such as short/common words) are only included once in the data.\n",
    "\n",
    "train.tsv contains the phrases and their associated sentiment labels. We have additionally provided a SentenceId so that you can track which phrases belong to a single sentence.\n",
    "test.tsv contains just phrases. You must assign a sentiment label to each phrase.\n",
    "The sentiment labels are:\n",
    "\n",
    "0 - negative\n",
    "1 - somewhat negative\n",
    "2 - neutral\n",
    "3 - somewhat positive\n",
    "4 - positive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Preparation\n",
    "\n",
    "Import necessary libraries and load the data using pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,GRU,LSTM,Embedding\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers import SpatialDropout1D,Dropout,Bidirectional,Conv1D,GlobalMaxPooling1D,MaxPooling1D,Flatten\n",
    "from keras.callbacks import ModelCheckpoint, TensorBoard, Callback, EarlyStopping\n",
    "from keras.utils import to_categorical\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_movie_data = pd.read_csv('Rotten_Tomatoes_Dataset/train.tsv', sep = '\\t')\n",
    "test_movie_data = pd.read_csv('Rotten_Tomatoes_Dataset/test.tsv', sep = '\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Data Exploration\n",
    "\n",
    "- Draw classes distribution: we can see that there are an imbalance between classes, most sentences are labeled with natural sentiment. Thus we will use matrics of f1-score, precision, recall instead of accuracy\n",
    "- Draw the most frequent words in negative sentences and positive sentences. We can see that, there are many punctuation and common words which are not usefull in sentiment analysis. We will remove them in the data preprocessing step.\n",
    "- We count the number of words in each sentence then draw the distribution of length of sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['PhraseId', 'SentenceId', 'Phrase', 'Sentiment'], dtype='object')"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_movie_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PhraseId       int64\n",
       "SentenceId     int64\n",
       "Phrase        object\n",
       "Sentiment      int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_movie_data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(156060, 4) (66292, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PhraseId</th>\n",
       "      <th>SentenceId</th>\n",
       "      <th>Phrase</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>A series of escapades demonstrating the adage ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>A series of escapades demonstrating the adage ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>A series</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>series</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>of escapades demonstrating the adage that what...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>of</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>escapades demonstrating the adage that what is...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>escapades</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>demonstrating the adage that what is good for ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PhraseId  SentenceId                                             Phrase  \\\n",
       "0         1           1  A series of escapades demonstrating the adage ...   \n",
       "1         2           1  A series of escapades demonstrating the adage ...   \n",
       "2         3           1                                           A series   \n",
       "3         4           1                                                  A   \n",
       "4         5           1                                             series   \n",
       "5         6           1  of escapades demonstrating the adage that what...   \n",
       "6         7           1                                                 of   \n",
       "7         8           1  escapades demonstrating the adage that what is...   \n",
       "8         9           1                                          escapades   \n",
       "9        10           1  demonstrating the adage that what is good for ...   \n",
       "\n",
       "   Sentiment  \n",
       "0          1  \n",
       "1          2  \n",
       "2          2  \n",
       "3          2  \n",
       "4          2  \n",
       "5          2  \n",
       "6          2  \n",
       "7          2  \n",
       "8          2  \n",
       "9          2  "
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(train_movie_data.shape, test_movie_data.shape)\n",
    "train_movie_data.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classes Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Number of reviews')"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sentiment_count = train_movie_data['Sentiment'].value_counts()\n",
    "\n",
    "plt.figure(figsize=(5,5))\n",
    "plt.bar(sentiment_count.index, sentiment_count.values)\n",
    "plt.xlabel('Sentiment')\n",
    "plt.ylabel('Number of reviews')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Words Frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  For negative sentence\n",
    "def get_all_words(sentenses):\n",
    "    for sentense in sentenses:\n",
    "        for word in sentense.split():\n",
    "            yield word\n",
    "\n",
    "neg_sentenses = train_movie_data[train_movie_data['Sentiment'] == 0]['Phrase']\n",
    "all_neg_words = get_all_words(neg_sentenses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(',', 3722), ('the', 3070), ('a', 2572), ('and', 2507), ('of', 2236), ('.', 1973), ('to', 1880), ('is', 1363), (\"'s\", 1136), ('that', 1130), ('in', 998), ('it', 927), ('movie', 757), ('as', 738), ('this', 576), ('for', 509), ('its', 488), ('film', 477), ('with', 437), (\"n't\", 424)]\n"
     ]
    }
   ],
   "source": [
    "from nltk import FreqDist\n",
    "\n",
    "freq_dist_neg = FreqDist(all_neg_words)\n",
    "print(freq_dist_neg.most_common(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(',', 4879), ('and', 3968), ('the', 3819), ('a', 3311), ('of', 3022), ('.', 2280), ('is', 1547), ('to', 1540), (\"'s\", 1329), ('that', 1248), ('in', 1045), ('film', 930), ('with', 912), ('it', 739), ('as', 713), ('an', 664), ('movie', 564), ('for', 553), ('A', 520), ('its', 516)]\n"
     ]
    }
   ],
   "source": [
    "#  For positive sentence\n",
    "\n",
    "pos_sentenses = train_movie_data[train_movie_data['Sentiment'] == 4]['Phrase']\n",
    "all_pos_words = get_all_words(pos_sentenses)\n",
    "\n",
    "freq_dist_pos = FreqDist(all_pos_words)\n",
    "print(freq_dist_pos.most_common(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Length of Sentences Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fb6e2244908>"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_movie_data['LengthSentence'] = train_movie_data['Phrase'].apply(lambda x: len(x.split()))\n",
    "train_movie_data['LengthSentence'].plot(kind = 'hist')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Data Pre-Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lower case\n",
    "We need to lower case all words in sentences that to avoid having many copies of the same words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_movie_data['Phrase'] = train_movie_data['Phrase'].apply(lambda x: \" \".join(w.lower() for w in x.split()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing Puntuation\n",
    "Punctuations are useless in sentiment analysis, therefore we should remove them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_movie_data['Phrase'] = train_movie_data['Phrase'].str.replace('[^\\w\\s]','')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing Stop Words\n",
    "Stop words are commonly occurring words that should be removed in this context because they are also useless in sentiment alanysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "\n",
    "SW = stopwords.words('english')\n",
    "train_movie_data['Phrase'] = train_movie_data['Phrase'].apply(lambda x: \" \".join(w for w in x.split() if w not in SW))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lemmatization\n",
    "we dont want a word can be in different forms, for example (go, goes, went, gone). It can make the vocabulary and vectorizer bigger, but dont have any extra meaning in sentiment analysis.\n",
    "\n",
    "Lemmatization is a method that converts the word into its root word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import Word\n",
    "train_movie_data['Phrase'] = train_movie_data['Phrase'].apply(lambda x: \" \".join([Word(word).lemmatize() for word in x.split()]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Words frequency\n",
    "After counting the most frequent words in negative sentences and positive sentences, we can see that there are some words like \"movie\" and \"film\" occurred mostly but dont have any effect in sentiment analysis.\n",
    "\n",
    "Therefore we should use Tfidf-vectorizer instead of CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "movie        829\n",
       "film         542\n",
       "bad          434\n",
       "nt           424\n",
       "like         324\n",
       "one          288\n",
       "character    227\n",
       "time         183\n",
       "make         182\n",
       "comedy       174\n",
       "story        164\n",
       "even         164\n",
       "minute       161\n",
       "would        146\n",
       "worst        145\n",
       "feel         139\n",
       "plot         135\n",
       "dull         134\n",
       "rrb          131\n",
       "way          131\n",
       "dtype: int64"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neg_freq = pd.Series(' '.join(train_movie_data[train_movie_data['Sentiment'] == 0]['Phrase']).split()).value_counts()[:20]\n",
    "neg_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "film            1091\n",
       "movie            746\n",
       "one              507\n",
       "performance      472\n",
       "best             370\n",
       "funny            345\n",
       "good             294\n",
       "story            280\n",
       "work             274\n",
       "year             264\n",
       "comedy           257\n",
       "make             247\n",
       "great            220\n",
       "character        207\n",
       "love             202\n",
       "well             169\n",
       "entertaining     168\n",
       "fun              165\n",
       "time             163\n",
       "life             162\n",
       "dtype: int64"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_freq = pd.Series(' '.join(train_movie_data[train_movie_data['Sentiment'] == 4]['Phrase']).split()).value_counts()[:20]\n",
    "pos_freq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Test Splitting\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = train_movie_data['Sentiment']\n",
    "X_train , X_val , y_train , y_val = train_test_split(train_movie_data['Phrase'],y,test_size = 0.20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vectorize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import TweetTokenizer\n",
    "tokenizer = TweetTokenizer()\n",
    "\n",
    "vectorizer = TfidfVectorizer(ngram_range=(1, 3), tokenizer=tokenizer.tokenize)\n",
    "vectorizer.fit(X_train)\n",
    "train_vectorized = vectorizer.transform(X_train)\n",
    "val_vectorized = vectorizer.transform(X_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Model Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.40      0.49      0.44      1084\n",
      "           1       0.50      0.57      0.53      4917\n",
      "           2       0.81      0.73      0.77     17772\n",
      "           3       0.52      0.57      0.55      5938\n",
      "           4       0.43      0.54      0.48      1501\n",
      "\n",
      "    accuracy                           0.66     31212\n",
      "   macro avg       0.53      0.58      0.55     31212\n",
      "weighted avg       0.68      0.66      0.66     31212\n",
      "\n",
      "0.6550685633730616\n"
     ]
    }
   ],
   "source": [
    "svm = LinearSVC()\n",
    "svm.fit(train_vectorized,y_train)\n",
    "print(classification_report( svm.predict(val_vectorized) , y_val))\n",
    "print(accuracy_score( svm.predict(val_vectorized) , y_val ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_features = 13000\n",
    "max_words = 50\n",
    "batch_size = 128\n",
    "epochs = 3\n",
    "num_classes=5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=max_features)\n",
    "tokenizer.fit_on_texts(list(X_train))\n",
    "X_train = tokenizer.texts_to_sequences(X_train)\n",
    "X_val = tokenizer.texts_to_sequences(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train =pad_sequences(X_train, maxlen=max_words)\n",
    "X_val = pad_sequences(X_val, maxlen=max_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "\n",
    "y_train_cat = to_categorical(y_train)\n",
    "y_val_cat = to_categorical(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_10 (Embedding)     (None, None, 100)         1300000   \n",
      "_________________________________________________________________\n",
      "gru_13 (GRU)                 (None, None, 64)          31680     \n",
      "_________________________________________________________________\n",
      "gru_14 (GRU)                 (None, 32)                9312      \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 5)                 165       \n",
      "=================================================================\n",
      "Total params: 1,341,157\n",
      "Trainable params: 1,341,157\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_GRU=Sequential()\n",
    "model_GRU.add(Embedding(max_features,100,mask_zero=True))\n",
    "model_GRU.add(GRU(64,dropout=0.4,return_sequences=True))\n",
    "model_GRU.add(GRU(32,dropout=0.5,return_sequences=False))\n",
    "model_GRU.add(Dense(num_classes,activation='softmax'))\n",
    "model_GRU.compile(loss='categorical_crossentropy',optimizer=Adam(lr = 0.001),metrics=['accuracy'])\n",
    "model_GRU.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tuananh305/MALIS/Py3-Jupy/lib/python3.6/site-packages/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 124848 samples, validate on 31212 samples\n",
      "Epoch 1/3\n",
      "124848/124848 [==============================] - 142s 1ms/step - loss: 1.0532 - accuracy: 0.5885 - val_loss: 0.8960 - val_accuracy: 0.6449\n",
      "Epoch 2/3\n",
      "124848/124848 [==============================] - 150s 1ms/step - loss: 0.8549 - accuracy: 0.6579 - val_loss: 0.8674 - val_accuracy: 0.6571\n",
      "Epoch 3/3\n",
      "124848/124848 [==============================] - 145s 1ms/step - loss: 0.7961 - accuracy: 0.6799 - val_loss: 0.8520 - val_accuracy: 0.6605\n"
     ]
    }
   ],
   "source": [
    "history_GRU=model_GRU.fit(X_train, y_train_cat, validation_data=(X_val, y_val_cat),epochs=epochs, batch_size=batch_size, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31212/31212 [==============================] - 18s 587us/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.29      0.55      0.38       706\n",
      "           1       0.58      0.53      0.56      6020\n",
      "           2       0.79      0.75      0.77     16604\n",
      "           3       0.61      0.56      0.58      7152\n",
      "           4       0.27      0.69      0.39       730\n",
      "\n",
      "    accuracy                           0.66     31212\n",
      "   macro avg       0.51      0.62      0.54     31212\n",
      "weighted avg       0.68      0.66      0.67     31212\n",
      "\n",
      "0.6605151864667436\n"
     ]
    }
   ],
   "source": [
    "y_val_pred = model_GRU.predict_classes(X_val, verbose=1)\n",
    "print(classification_report( y_val_pred , y_val))\n",
    "print(accuracy_score( y_val_pred , y_val ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_11 (Embedding)     (None, None, 100)         1300000   \n",
      "_________________________________________________________________\n",
      "lstm_7 (LSTM)                (None, None, 64)          42240     \n",
      "_________________________________________________________________\n",
      "lstm_8 (LSTM)                (None, 32)                12416     \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 5)                 165       \n",
      "=================================================================\n",
      "Total params: 1,354,821\n",
      "Trainable params: 1,354,821\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_LSTM=Sequential()\n",
    "model_LSTM.add(Embedding(max_features,100,mask_zero=True))\n",
    "model_LSTM.add(LSTM(64,dropout=0.4,return_sequences=True))\n",
    "model_LSTM.add(LSTM(32,dropout=0.5,return_sequences=False))\n",
    "model_LSTM.add(Dense(num_classes,activation='softmax'))\n",
    "model_LSTM.compile(loss='categorical_crossentropy',optimizer=Adam(lr = 0.001),metrics=['accuracy'])\n",
    "model_LSTM.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tuananh305/MALIS/Py3-Jupy/lib/python3.6/site-packages/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 124848 samples, validate on 31212 samples\n",
      "Epoch 1/3\n",
      "124848/124848 [==============================] - 153s 1ms/step - loss: 1.0733 - accuracy: 0.5862 - val_loss: 0.9080 - val_accuracy: 0.6416\n",
      "Epoch 2/3\n",
      "124848/124848 [==============================] - 153s 1ms/step - loss: 0.8589 - accuracy: 0.6563 - val_loss: 0.8703 - val_accuracy: 0.6544\n",
      "Epoch 3/3\n",
      "124848/124848 [==============================] - 157s 1ms/step - loss: 0.8070 - accuracy: 0.6747 - val_loss: 0.8617 - val_accuracy: 0.6607\n"
     ]
    }
   ],
   "source": [
    "history_LMST=model_LSTM.fit(X_train, y_train_cat, validation_data=(X_val, y_val_cat),epochs=epochs, batch_size=batch_size, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31212/31212 [==============================] - 19s 602us/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.35      0.50      0.41       932\n",
      "           1       0.51      0.55      0.53      5168\n",
      "           2       0.83      0.73      0.78     18050\n",
      "           3       0.55      0.58      0.57      6255\n",
      "           4       0.28      0.65      0.39       807\n",
      "\n",
      "    accuracy                           0.66     31212\n",
      "   macro avg       0.50      0.60      0.54     31212\n",
      "weighted avg       0.69      0.66      0.67     31212\n",
      "\n",
      "0.6607074202229911\n"
     ]
    }
   ],
   "source": [
    "y_val_pred = model_LSTM.predict_classes(X_val, verbose=1)\n",
    "print(classification_report( y_val_pred , y_val))\n",
    "print(accuracy_score( y_val_pred , y_val ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
